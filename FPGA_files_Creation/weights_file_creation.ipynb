{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2b2f7fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 09:57:04.222989: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-21 09:57:04.226527: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-08-21 09:57:04.236060: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1755781024.251594  144236 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1755781024.256238  144236 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1755781024.268873  144236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755781024.268893  144236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755781024.268894  144236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1755781024.268896  144236 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-21 09:57:04.272840: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import models, layers, datasets\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape, Input, InputLayer\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.ops import math_ops\n",
    "import keras\n",
    "alphal0 = 1e-5\n",
    "beta = 20\n",
    "alphal2 = 1e-4\n",
    "REG = \"L2L0\"\n",
    "tf.keras.utils.get_custom_objects().clear()\n",
    "\n",
    "@tf.keras.utils.register_keras_serializable(package='Custom', name='L2L0_Reg')\n",
    "class L2L0_Reg(tf.keras.regularizers.Regularizer):\n",
    "\n",
    "  def __init__(self, l0=0., beta=0, l2=0.):  # pylint: disable=redefined-outer-name\n",
    "    self.l0 = K.cast_to_floatx(l0)\n",
    "    self.beta = K.cast_to_floatx(beta)\n",
    "    self.l2 = K.cast_to_floatx(l2)\n",
    "\n",
    "  def __call__(self, x):\n",
    "    # ones_tensor = tf.ones(x.shape)\n",
    "    if not self.l2 and not self.l0:\n",
    "      return K.constant(0.)\n",
    "    regularization = 0.\n",
    "    if self.l0:\n",
    "      ones_tensor = tf.ones(x.shape)\n",
    "      regularization += self.l0 * math_ops.reduce_sum(ones_tensor-math_ops.exp(-self.beta*math_ops.abs(x)))\n",
    "      # regularization += self.l0 * math_ops.reduce_sum( tf.clip_by_value(self.beta * math_ops.abs(x), 0, 1)  )\n",
    "    if self.l2:\n",
    "      regularization += self.l2 * math_ops.reduce_sum(math_ops.square(x))\n",
    "    return regularization\n",
    "\n",
    "  def get_config(self):\n",
    "    return {'l0': float(self.l0), 'beta': float(self.beta), 'l2': float(self.l2)}\n",
    "\n",
    "  @classmethod\n",
    "  def from_config(cls, config):\n",
    "      l0 = float(config.pop(\"l0\"))\n",
    "      beta = float(config.pop(\"beta\"))\n",
    "      l2 = float(config.pop(\"l2\"))\n",
    "      return cls(l0=l0,beta=beta,l2=l2)\n",
    "\n",
    "\n",
    "def l0reg(l0=0.0001, l2=0.001, beta=10):\n",
    "  return L2L0_Reg(l0=l0, beta=beta, l2=l2)\n",
    "\n",
    "def LeNet_NN_broken(MT):\n",
    "    \"\"\"\n",
    "    Define LeNet 300-100-10 Dense Fully Connected\n",
    "    Neural Network for MNIST multi-class classification\n",
    "    \"\"\"\n",
    "\n",
    "    model = keras.Sequential()\n",
    "\n",
    "    model.add(keras.layers.Input(shape=(28,28)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "\n",
    "    model.add(\n",
    "        Dense(units = MT, activation = None,\n",
    "              kernel_initializer = tf.initializers.GlorotNormal(),\n",
    "              input_shape = (784,),\n",
    "              kernel_regularizer=l0reg(l0=alphal0*np.sqrt(235500/266610),l2=alphal2,beta=beta) if REG != \"None\" else None\n",
    "             )\n",
    "    )\n",
    "    model.add(\n",
    "          Dense(units = 300, activation = 'relu',\n",
    "                kernel_initializer = tf.initializers.GlorotNormal(),\n",
    "                kernel_regularizer=l0reg(l0=alphal0*np.sqrt(30100/266610),l2=alphal2,beta=beta) if REG != \"None\" else None     \n",
    "\t\t  )\n",
    "\t)\n",
    "\n",
    "    model.add(\n",
    "        Dense(units = 100, activation = 'relu',\n",
    "              kernel_initializer = tf.initializers.GlorotNormal(),\n",
    "              kernel_regularizer=l0reg(l0=alphal0*np.sqrt(30100/266610),l2=alphal2,beta=beta) if REG != \"None\" else None\n",
    "             )\n",
    "    )\n",
    "\n",
    "    model.add(\n",
    "        Dense(units = 10, activation = None, kernel_regularizer=l0reg(l0=alphal0*np.sqrt(1010/266610),l2=alphal2,beta=beta) if REG != \"None\" else None\n",
    "             )\n",
    "    )\n",
    "    model.compile(\n",
    "\t\n",
    "  \tloss=tf.keras.losses.categorical_crossentropy,\n",
    "\t\t# optimizer='adam',\n",
    "\t\toptimizer=tf.keras.optimizers.Adam(learning_rate = 0.0012),\n",
    "\t\tmetrics=['accuracy'])\n",
    "  \n",
    "    return model\n",
    "\n",
    "def extract_weights_from_model(model):\n",
    "    # Extract weights from the model\n",
    "    model_weights = model.get_weights()\n",
    "    # Reshape and organize weights into a list of numpy arrays for each layer\n",
    "    weights = []\n",
    "    for layer_idx in range(0, len(model_weights), 2):\n",
    "        # Get the weight matrix and the bias vector\n",
    "        weight_matrix = model_weights[layer_idx]    # Shape: (input_neurons, output_neurons)\n",
    "        bias_vector = model_weights[layer_idx + 1]  # Shape: (output_neurons,)\n",
    "        # Combine weights and biases for each neuron\n",
    "        layer_weights = []\n",
    "        for neuron_idx in range(weight_matrix.shape[1]):  # Iterate through output neurons\n",
    "            neuron_weights = weight_matrix[:,neuron_idx]  # Get weights for each neuron\n",
    "            neuron_combined = np.append( bias_vector[neuron_idx],neuron_weights,)  # Append bias to the weights\n",
    "            layer_weights.append(neuron_combined)\n",
    "        \n",
    "        weights.append(np.array(layer_weights))  # Append all neuron weights for this layer\n",
    "\n",
    "    return (weights)\n",
    "\n",
    "   \n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "def float_to_fixed_32(number: float,decimal_bits = 28) -> np.int32:\n",
    "    \"\"\"\n",
    "    Returns: 32-bit signed integer (usable as uint32 in hardware).\n",
    "    \"\"\"\n",
    "    scaled = number * (2**decimal_bits) # Multiply by 2^16\n",
    "    fixed = int(np.round(scaled))  # Round to nearest integer\n",
    "    \n",
    "    # Handle overflow (optional)\n",
    "    fixed = np.int32(fixed)  # Force 32-bit signed integer\n",
    "    return fixed\n",
    "\n",
    "def to_32bit_hex(value):\n",
    "    \"\"\"Convert a signed integer to 32-bit hex string (SystemVerilog compatible).\"\"\"\n",
    "    return f\"32'h{value & 0xFFFFFFFF:08X}\"  # Mask to 32 bits, uppercase, zero-padded\n",
    "\n",
    "# Original arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96cdd331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32'h7FFFFFFF\n"
     ]
    }
   ],
   "source": [
    "print(to_32bit_hex(2147483647))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee3c0dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-21 09:57:06.684156: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_303\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_303\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_303 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1212 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,045</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1213 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1214 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1215 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_303 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1212 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │        \u001b[38;5;34m29,045\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1213 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │        \u001b[38;5;34m11,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1214 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1215 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,555</span> (279.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m71,555\u001b[0m (279.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,555</span> (279.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m71,555\u001b[0m (279.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lenet = load_model('/home/isi/Documents/Mestrado/SVD_tests/brokenLeNet.h5')\n",
    "weights_lenet = extract_weights_from_model(lenet)\n",
    "#generate_svd_sv_weights(weights_lenet, \"lenet_weights.vhd\")\n",
    "lenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6f110e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer flatten_303 does not have weights.\n",
      "Layer: dense_1212\n",
      "Layer: dense_1213\n",
      "Layer: dense_1214\n",
      "Layer: dense_1215\n",
      " | |VT(37,37) |US(784,37) )\n",
      " | |VT(300,300) |US(37,37) )\n",
      " | |VT(100,100) |US(300,100) )\n",
      " | |VT(10,10) |US(100,10) )\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "biases  = []\n",
    "for layer in lenet.layers:\n",
    "    # Check if the layer has weights\n",
    "    if len(layer.get_weights()) > 0:\n",
    "        weights.append(layer.get_weights()[0])  # Extract the weight matrix\n",
    "        biases.append(layer.get_weights()[1])\n",
    "        print(f\"Layer: {layer.name}\")\n",
    "        #print(f\"Weights matrix shape: {weights[-1].shape}\")\n",
    "        #print(weights[-1])  # Display the weight matrix\n",
    "        #print(\"=\"*50)\n",
    "    else:\n",
    "        print(f\"Layer {layer.name} does not have weights.\")\n",
    "\n",
    "#%%\n",
    "# Make SVD Conversion for each layer\n",
    "U, S, VT, US = [],[],[],[]\n",
    "for weight in weights:\n",
    "    t_U , t_S , t_VT = np.linalg.svd(weight)\n",
    "    t_US = np.zeros_like(t_U)\n",
    "    for i in range(len(t_S)):\n",
    "        t_US[:,i] = t_U[:,i]*t_S[i]\n",
    "    t_US = t_US[:,:len(t_S)]\n",
    "    t_Vt_send = t_VT[:len(t_S),:]\n",
    "    U.append(t_U)\n",
    "    S.append(t_S)\n",
    "    VT.append(t_Vt_send)\n",
    "    US.append(t_US)\n",
    "    print(f\" | |VT({len(t_VT)},{len(t_VT[0])}) |US({len(t_US)},{len(t_US[0])}) )\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1b6bd222",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_to_fixed_32(x):\n",
    "    if x > 1 :\n",
    "        x = 1\n",
    "        print(\"Number bigger than one\")\n",
    "    if x < -1 :\n",
    "        x = -1\n",
    "        print(\"Number smaller than minus one\")\n",
    "    return int((x*(2)**31) - 1) if x != 0 else 0\n",
    "\n",
    "\n",
    "def write_sv_signed_array(array,template,only_numbers):\n",
    "    array_string = \"\"\n",
    "    arr_string = \"\"\n",
    "    for i,x in enumerate(array):\n",
    "        last_char = \" , \" if i < len(array) - 1 else \"\"\n",
    "        arr_string+= to_32bit_hex(int(norm_to_fixed_32(x))) + last_char\n",
    "    if (only_numbers == False):\n",
    "        array_string += f\"logic signed [31:0] \"+ template + f\"[{len(array)}] = '{{{arr_string}}};\\n\"\n",
    "    else :\n",
    "        array_string += arr_string\n",
    "    return array_string\n",
    "\n",
    "\n",
    "def write_sv_signed_matrix(matrix,template):\n",
    "    \n",
    "    matrix_string = \"\\nlogic signed [31:0] \"+template+f\" [{matrix.shape[0]}][{matrix.shape[1]}]\"+\" ='{\\n\"\n",
    "\n",
    "    for i,arr in enumerate(matrix):\n",
    "        last_char = \" , \" if i < matrix.shape[0] - 1 else \"\"\n",
    "        matrix_string+= \"{\" + write_sv_signed_array(arr,'',True) + \"}\" +last_char + \"\\n\"\n",
    "    matrix_string+='};\\n'\n",
    "    \n",
    "    return matrix_string\n",
    "\n",
    "\n",
    "def generate_svd_sv_weights(VT,US,biases, file_name):\n",
    "    sv_template = \"\"\"\n",
    "\n",
    "package model_weights;\n",
    "\n",
    "{weight_constants}\n",
    "\n",
    "endpackage\n",
    "\"\"\"\n",
    "    weight_constants = \"\"\n",
    "    \n",
    "    for i,v in enumerate(VT):\n",
    "        weight_constants+=write_sv_signed_matrix(v,f\"VT_{i}\")\n",
    "        print(v.shape)\n",
    "    \n",
    "    \n",
    "    for i,us in enumerate(US):\n",
    "        us_np = np.array(us)\n",
    "        weight_constants+=write_sv_signed_matrix(us_np,f\"US_{i}\")\n",
    "        print(us_np.shape)\n",
    "\n",
    "\n",
    "    for i,b in enumerate(biases):\n",
    "        weight_constants+=write_sv_signed_array(b,f\"bias_{i}\",False)\n",
    "        \n",
    "    sv_code = sv_template.format(\n",
    "        weight_constants=weight_constants\n",
    "    )\n",
    "    with open(file_name, \"w\") as sv_file:\n",
    "        sv_file.write(sv_code)\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have extracted weights from your neural network model\n",
    "# Here, weights is a list of numpy arrays representing the weights for each layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9213698d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 37)\n",
      "(37, 300)\n",
      "(100, 100)\n",
      "(10, 10)\n",
      "Number bigger than one\n",
      "Number smaller than minus one\n",
      "Number bigger than one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "(784, 37)\n",
      "(37, 37)\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number bigger than one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number bigger than one\n",
      "Number bigger than one\n",
      "Number smaller than minus one\n",
      "Number bigger than one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number bigger than one\n",
      "Number bigger than one\n",
      "Number bigger than one\n",
      "Number smaller than minus one\n",
      "Number bigger than one\n",
      "Number smaller than minus one\n",
      "Number bigger than one\n",
      "(300, 100)\n",
      "Number bigger than one\n",
      "Number bigger than one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number smaller than minus one\n",
      "Number bigger than one\n",
      "Number bigger than one\n",
      "Number smaller than minus one\n",
      "Number bigger than one\n",
      "Number bigger than one\n",
      "Number smaller than minus one\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "generate_svd_sv_weights(VT,US,biases,\"svd_values.sv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "478ca9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_with_numpy(nested_list):\n",
    "\n",
    "    result = []\n",
    "    \n",
    "    for inner_list in nested_list:   \n",
    "        arr = np.array(inner_list)\n",
    "        max_val = abs(arr).max()\n",
    "        \n",
    "        \n",
    "        if max_val == 0:\n",
    "            normalized = np.zeros_like(arr, dtype=float)\n",
    "        else:\n",
    "            normalized = arr/(max_val*1.000001)\n",
    "        result.append(normalized)\n",
    "    \n",
    "    return result , 1/(max_val*1.000001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f2dd62a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37, 37)\n",
      "(37, 300)\n",
      "(100, 100)\n",
      "(10, 10)\n",
      "(784, 37)\n",
      "(37, 37)\n",
      "(300, 100)\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "#Normalizar cada matriz de pesos\n",
    "\n",
    "\n",
    "VT_n ,alpha= normalize_with_numpy(VT)\n",
    "US_n ,beta= normalize_with_numpy(US)\n",
    "#print(alpha,beta)\n",
    "biases_n = []\n",
    "for bias in biases:\n",
    "    biases_n.append(bias*alpha*beta)\n",
    "\n",
    "#print(VT[0].max(),VT[0].min())\n",
    "#print(VT_n[0][1,1],VT[0][1,1])\n",
    "generate_svd_sv_weights(VT_n,US_n,biases_n,\"svd_values_norm.sv\")\n",
    "#print(US[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54dbfee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizar por um fator comum entre todas as variaveis\n",
    "def normalize_general(VT,US,biases):\n",
    "    result_VT,result_US,result_biases = []\n",
    "    \n",
    "    for inner_list in nested_list:   \n",
    "        arr = np.array(inner_list)\n",
    "        max_val = abs(arr).max()\n",
    "        \n",
    "        \n",
    "        if max_val == 0:\n",
    "            normalized = np.zeros_like(arr, dtype=float)\n",
    "        else:\n",
    "            normalized = arr/(max_val*1.000001)\n",
    "        result.append(normalized)\n",
    "    \n",
    "    return result , 1/(max_val*1.000001)\n",
    "\n",
    "VT_n ,alpha= normalize_with_numpy(VT)\n",
    "US_n ,beta= normalize_with_numpy(US)\n",
    "#print(alpha,beta)\n",
    "biases_n = []\n",
    "for bias in biases:\n",
    "    biases_n.append(bias*alpha*beta)\n",
    "\n",
    "#print(VT[0].max(),VT[0].min())\n",
    "#print(VT_n[0][1,1],VT[0][1,1])\n",
    "generate_svd_sv_weights(VT_n,US_n,biases_n,\"svd_values_norm.sv\")\n",
    "#print(US[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "197d8038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26857463  0.11653159 -0.03921171  0.3379265  -0.11215492 -0.05069784\n",
      " -0.01574498 -0.07947755 -0.04679665 -0.13859864 -0.17103831  0.11341953\n",
      "  0.29205248 -0.01493471 -0.13107313  0.01520232 -0.0174751   0.05377271\n",
      " -0.33874756 -0.00943521 -0.01615655 -0.08488752  0.33888295  0.05655032\n",
      "  0.19301003 -0.01016331 -0.03299653  0.02159429 -0.01120275  0.41458073\n",
      " -0.0205394   0.09969426 -0.20669778 -0.07146092 -0.0085628   0.02664064\n",
      "  0.19696796 -0.21724004 -0.07529428  0.00544734 -0.19035766 -0.07074089\n",
      " -0.01662887  0.04591956  0.31902382  0.36379084 -0.00366823 -0.00825527\n",
      "  0.08657182 -0.06879878 -0.04655615 -0.02881224 -0.0990693   0.15883671\n",
      " -0.06439045 -0.00712355 -0.03220049 -0.04481666 -0.00914741 -0.50608665\n",
      " -0.03217473 -0.02538256 -0.04552635 -0.01192292  0.15831415 -0.04273221\n",
      " -0.10854637  0.0268755  -0.01593244 -0.3005913  -0.08288822 -0.24838582\n",
      " -0.02632396 -0.01005456 -0.01806499 -0.3336969  -0.09432822 -0.01424101\n",
      "  0.18302883 -0.1520102  -0.10035869  0.2509785  -0.07188867 -0.0339052\n",
      " -0.3384106   0.17983332 -0.40086254 -0.14297478 -0.18598711 -0.26390094\n",
      " -0.01397317  0.24175906 -0.02181219 -0.29345107 -0.16578339 -0.01578764\n",
      " -0.01044108 -0.02439234 -0.08805943  0.07708232  0.2761848  -0.01821056\n",
      " -0.35433647  0.06728865  0.4173812  -0.01435129 -0.24410243 -0.01195409\n",
      "  0.14964     0.36248878 -0.03243265  0.41864836 -0.10766402 -0.05650862\n",
      " -0.33469027  0.10805871 -0.28173378 -0.00995513  0.08028661 -0.02881016\n",
      " -0.15009868 -0.05272995 -0.16695625 -0.13446145  0.13436018 -0.05583381\n",
      " -0.02833684 -0.01823712 -0.0089433  -0.0364944  -0.02775235 -0.02611762\n",
      "  0.09913846 -0.05763981 -0.02653462  0.378256    0.12008633 -0.01391187\n",
      " -0.01391133 -0.17417477 -0.07514464 -0.01676693 -0.04225368  0.21818495\n",
      "  0.25660348 -0.10212707 -0.13234095 -0.00851657 -0.15792616 -0.05828892\n",
      " -0.0787128  -0.2005951  -0.01053711 -0.07030119 -0.10943152 -0.02035353\n",
      "  0.0816573  -0.40241742 -0.14296529 -0.05405069 -0.01848589 -0.37092584\n",
      " -0.05762487  0.11680964  0.13282385 -0.01698649  0.16304916 -0.04765931\n",
      " -0.03796296 -0.11858556 -0.20872575 -0.10045835 -0.01170126 -0.08198962\n",
      " -0.16843872 -0.19803806  0.2219266  -0.15369067  0.05887632 -0.13703237\n",
      " -0.21019731 -0.02037915 -0.05519481 -0.01339196 -0.10231905  0.23811388\n",
      " -0.17303221 -0.05928164  0.38805947  0.18190154 -0.01629845 -0.20114788\n",
      "  0.15308285 -0.0796495  -0.04810602 -0.01152115 -0.21457097 -0.19379641\n",
      " -0.22064206 -0.02769594 -0.03834671 -0.00872109 -0.01349484 -0.0149306\n",
      " -0.11022815 -0.14382163  0.05072037 -0.00129796 -0.1522539   0.03152772\n",
      " -0.00796497 -0.01362223 -0.00971263 -0.06799939 -0.02345108 -0.17339306\n",
      "  0.02784933  0.12548572 -0.02138575 -0.00981284 -0.02806247 -0.02620787\n",
      "  0.08989096 -0.10360283 -0.03196925 -0.0371065  -0.02545987 -0.1275617\n",
      "  0.15497597 -0.15647474 -0.0114952  -0.00751181 -0.00777618 -0.25859022\n",
      "  0.08158189 -0.01156757 -0.01258501 -0.10138296 -0.01746696 -0.41853496\n",
      " -0.02144954  0.34563962 -0.01422665 -0.00175467 -0.11834008 -0.14216197\n",
      "  0.37811834 -0.06451129 -0.1490962  -0.23758838 -0.01114819  0.4111463\n",
      " -0.09640305  0.01382196  0.10084686  0.24376208 -0.12621658 -0.02798637\n",
      " -0.05468936 -0.10357284  0.1711997  -0.19594027 -0.28552324 -0.02511807\n",
      " -0.02477909 -0.01140575 -0.08651619 -0.05362956 -0.27091086  0.09090588\n",
      " -0.02393461 -0.02153333 -0.00696794 -0.1439364   0.2833683   0.01251866\n",
      " -0.03103722  0.00380265 -0.3909756  -0.02411854 -0.01737023 -0.11963589\n",
      " -0.03734555 -0.07417985 -0.03050532 -0.1549872  -0.4774242  -0.07903407\n",
      "  0.06121509 -0.2938148  -0.32488906 -0.01803693 -0.01263414 -0.09827661\n",
      "  0.19826844 -0.23485298 -0.08936901  0.08117363 -0.07293184 -0.04347133]\n"
     ]
    }
   ],
   "source": [
    "print(biases[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ee727bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.23558792  0.10221902 -0.03439568  0.29642195 -0.0983799  -0.04447107\n",
      " -0.01381116 -0.06971601 -0.04104903 -0.12157577 -0.15003116  0.09948918\n",
      "  0.2561822  -0.01310041 -0.11497456  0.01333516 -0.01532879  0.04716827\n",
      " -0.29714215 -0.00827637 -0.01417218 -0.07446152  0.2972609   0.04960473\n",
      "  0.16930428 -0.00891504 -0.02894386  0.01894205 -0.00982681  0.36366138\n",
      " -0.01801672  0.08744968 -0.18131088 -0.06268399 -0.0075111   0.0233686\n",
      "  0.1727761  -0.19055833 -0.06604654  0.00477829 -0.16697767 -0.0620524\n",
      " -0.01458649  0.04027966  0.2798409   0.31910956 -0.0032177  -0.00724135\n",
      "  0.07593895 -0.06034882 -0.04083806 -0.02527348 -0.08690147  0.13932817\n",
      " -0.05648193 -0.00624862 -0.02824559 -0.03931222 -0.00802392 -0.44392842\n",
      " -0.02822299 -0.02226504 -0.03993474 -0.01045854  0.13886979 -0.03748379\n",
      " -0.09521455  0.02357462 -0.01397559 -0.26367226 -0.07270779 -0.21787874\n",
      " -0.02309082 -0.00881965 -0.01584622 -0.2927118  -0.08274271 -0.01249191\n",
      "  0.16054899 -0.1333401  -0.08803251  0.22015299 -0.06305921 -0.02974092\n",
      " -0.29684657  0.15774596 -0.35162807 -0.12541443 -0.16314393 -0.23148827\n",
      " -0.01225697  0.21206589 -0.01913319 -0.25740904 -0.14542165 -0.01384858\n",
      " -0.00915869 -0.02139644 -0.07724385  0.06761497  0.24226342 -0.01597392\n",
      " -0.3108164   0.05902417  0.3661179  -0.01258864 -0.21412145 -0.01048588\n",
      "  0.13126102  0.3179674  -0.02844923  0.3672294  -0.09444059 -0.04956815\n",
      " -0.29358318  0.09478679 -0.24713087 -0.00873242  0.0704257  -0.02527166\n",
      " -0.13166337 -0.04625358 -0.14645046 -0.11794672  0.11785788 -0.04897623\n",
      " -0.02485647 -0.01599721 -0.00784487 -0.03201211 -0.02434377 -0.02290982\n",
      "  0.08696215 -0.05056042 -0.02327561  0.3317981   0.10533717 -0.0122032\n",
      " -0.01220273 -0.1527824  -0.06591528 -0.0147076  -0.03706403  0.19138718\n",
      "  0.2250871  -0.08958368 -0.11608666 -0.00747056 -0.13852945 -0.0511298\n",
      " -0.06904519 -0.17595774 -0.00924293 -0.0616667  -0.09599099 -0.01785368\n",
      "  0.07162804 -0.35299197 -0.1254061  -0.04741212 -0.01621542 -0.32536823\n",
      " -0.05054731  0.10246293  0.11651026 -0.01490019  0.14302325 -0.04180573\n",
      " -0.0333003  -0.10402073 -0.1830898  -0.08811992 -0.01026409 -0.07191955\n",
      " -0.14775085 -0.17371476  0.19466928 -0.13481417  0.05164505 -0.12020188\n",
      " -0.1843806  -0.01787615 -0.04841571 -0.01174714 -0.08975209  0.20886841\n",
      " -0.15178016 -0.05200059  0.3403975   0.15956016 -0.01429666 -0.17644264\n",
      "  0.13428101 -0.06986684 -0.04219757 -0.01010611 -0.18821709 -0.16999409\n",
      " -0.19354251 -0.02429429 -0.03363692 -0.00764996 -0.01183739 -0.0130968\n",
      " -0.09668978 -0.12615727  0.04449083 -0.00113854 -0.13355386  0.02765545\n",
      " -0.0069867  -0.01194913 -0.00851971 -0.05964762 -0.02057079 -0.15209669\n",
      "  0.02442884  0.1100734  -0.01875913 -0.00860762 -0.0246158  -0.02298899\n",
      "  0.07885044 -0.0908782  -0.02804274 -0.03254903 -0.02233286 -0.11189441\n",
      "  0.13594161 -0.13725631 -0.01008334 -0.0065892  -0.0068211  -0.22682983\n",
      "  0.0715619  -0.01014682 -0.0110393  -0.08893097 -0.01532164 -0.36712992\n",
      " -0.01881508  0.3031877  -0.01247932 -0.00153916 -0.10380539 -0.12470145\n",
      "  0.33167735 -0.05658793 -0.130784   -0.20840746 -0.00977895  0.36064878\n",
      " -0.0845627   0.01212433  0.08846071  0.2138229  -0.11071449 -0.02454905\n",
      " -0.04797234 -0.09085188  0.15017273 -0.17187464 -0.2504549  -0.02203304\n",
      " -0.02173568 -0.01000488 -0.07589015 -0.04704271 -0.23763722  0.0797407\n",
      " -0.02099493 -0.01888858 -0.00611213 -0.12625794  0.24856463  0.0109811\n",
      " -0.02722518  0.0033356  -0.34295547 -0.02115627 -0.01523679 -0.10494205\n",
      " -0.03275872 -0.06506898 -0.02675861 -0.13595146 -0.41878635 -0.069327\n",
      "  0.05369657 -0.25772807 -0.28498575 -0.01582161 -0.0110824  -0.08620615\n",
      "  0.17391686 -0.20600803 -0.07839259  0.07120378 -0.06397425 -0.03813213]\n"
     ]
    }
   ],
   "source": [
    "print(biases_n[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bb1df687",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd68481",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (60000, 28, 28) (1, 28, 28, 1)\n",
      "Test data shape: (10000, 28, 28) (10000,)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step\n",
      "(784, 1)\n",
      "<class 'list'> None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_144236/4100426010.py:6: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  return int((x*(2)**31) - 1) if x != 0 else 0\n"
     ]
    }
   ],
   "source": [
    "#Compile lenet model\n",
    "lenet.compile(optimizer='adam',loss='mean_squared_error')\n",
    "\n",
    "#Load MNIST Dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize pixel values (0-255 → 0-1)\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "#Select One image\n",
    "img_processed = train_images[0].reshape(1, 28, 28, 1)\n",
    "img_processed_tb = img_processed.reshape(-1,1)\n",
    "print(\"Training data shape:\", train_images.shape, img_processed.shape)  # (60000, 28, 28)\n",
    "print(\"Test data shape:\", test_images.shape , test_labels.shape)       # (10000, 28, 28)\n",
    "#Predict Output\n",
    "result = lenet.predict(img_processed)\n",
    "\n",
    "#Convert to .csv, read and store in array on testbench\n",
    "print(img_processed_tb.shape)\n",
    "#X_tb = list(np.zeros_like(img_processed_tb))\n",
    "X_tb = []\n",
    "for i,x in enumerate(img_processed_tb):\n",
    "    X_tb.append(int(norm_to_fixed_32(x)))\n",
    "\n",
    "print(type(X_tb),(X_tb.reverse()))\n",
    "np.savetxt('mnist_pixel_data.csv', \n",
    "           X_tb[::-1], \n",
    "           fmt='%X',          # Decimal format\n",
    "           delimiter=',',     # Comma-separated\n",
    "           header='',         # No header\n",
    "           comments='')       # No comment characters\n",
    "\n",
    "X_tb_layer2 = []\n",
    "\n",
    "for i,x in enumerate(img_processed_tb):\n",
    "    X_tb.append(int(norm_to_fixed_32(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2448dc3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.6715745e-15 4.7046100e-10 5.9327407e-13 2.1920911e-04 8.9815265e-22\n",
      "  9.9978083e-01 1.9406104e-18 5.7118121e-12 7.6158898e-16 2.4271533e-11]]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_303\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_303\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_303 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1212 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">37</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">29,045</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1213 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">300</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">11,400</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1214 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">30,100</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1215 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ flatten_303 (\u001b[38;5;33mFlatten\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1212 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m37\u001b[0m)             │        \u001b[38;5;34m29,045\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1213 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m300\u001b[0m)            │        \u001b[38;5;34m11,400\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1214 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m)            │        \u001b[38;5;34m30,100\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1215 (\u001b[38;5;33mDense\u001b[0m)              │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)             │         \u001b[38;5;34m1,010\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,555</span> (279.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m71,555\u001b[0m (279.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">71,555</span> (279.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m71,555\u001b[0m (279.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(result)\n",
    "lenet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "97984f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "088ab0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/isi/.local/lib/python3.10/site-packages/keras/src/layers/core/dense.py:93: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "w0 = lenet.layers[1].get_weights()\n",
    "w1 = lenet.layers[2].get_weights()\n",
    "modelflayer = keras.Sequential()\n",
    "\n",
    "modelflayer.add(keras.layers.Input(shape=(28,28)))\n",
    "modelflayer.add(Flatten())\n",
    "modelflayer.add(\n",
    "    Dense(units = 37, activation = None,\n",
    "          kernel_initializer = tf.initializers.GlorotNormal(),\n",
    "          input_shape = (784,),\n",
    "          kernel_regularizer=l0reg(l0=alphal0*np.sqrt(235500/266610),l2=alphal2,beta=beta) if REG != \"None\" else None\n",
    "         )\n",
    "\n",
    ")\n",
    "\n",
    "modelflayer.layers[1].set_weights(w0)\n",
    "test_1 = modelflayer.predict(img_processed)\n",
    "modelflayer.add(\n",
    "    Dense(units = 300, activation = \"relu\",\n",
    "          kernel_initializer = tf.initializers.GlorotNormal(),\n",
    "          input_shape = (37,),\n",
    "          kernel_regularizer=l0reg(l0=alphal0*np.sqrt(235500/266610),l2=alphal2,beta=beta) if REG != \"None\" else None\n",
    "         )\n",
    ")\n",
    "#test_2 = modelflayer.predict(img_processed)\n",
    "#modelflayer.layers[2].set_weights(w1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d587fe20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.3235943   5.337052    1.686502   -2.9129078   2.8752513   1.7589655\n",
      "  3.8717318   0.64927065  3.090874   -0.36634356 -0.42473787 -1.9393029\n",
      " -3.5138793  -0.02679098  1.678901    2.8468308  -1.1673747   4.7979307\n",
      " -2.5374403   3.1928668   1.5989801  -2.4882338   4.5781097  -0.1746226\n",
      "  7.128281   -1.8107544  -1.1275764   1.8484052   0.94436884 -1.4971018\n",
      " -3.0385048   0.09838134  3.43033     0.01653632  2.7478933  -1.1405938\n",
      " -1.4388838 ]\n",
      "[ 0.3259681   0.74871445  0.23659286 -0.4086406   0.40335792  0.24675849\n",
      "  0.5431503   0.09108368  0.43360677 -0.05139292 -0.05958484 -0.27205732\n",
      " -0.49294856 -0.0037584   0.23552655  0.3993709  -0.1637665   0.6730832\n",
      " -0.3559677   0.44791496  0.22431475 -0.34906474  0.64224535 -0.02449713\n",
      "  0.99999905 -0.25402376 -0.15818334  0.25930566  0.13248186 -0.21002263\n",
      " -0.4262601   0.01380154  0.48122776  0.00231982  0.38549137 -0.1600095\n",
      " -0.20185545]\n",
      "<class 'list'>\n",
      "[700011136, 1607852032, 508079296, 3417418304, 866204544, 529909824, 1166406400, 195600704, 931163456, 4184601832, 4167009832, 3710728640, 3236368320, 4286896186, 505789408, 857642496, 3943281408, 1445435136, 3530532480, 961890048, 481712256, 3545356480, 1379211392, 4242360108, 2147481600, 3749455424, 3955271168, 556854656, 284502624, 3843947136, 3379580672, 29638576, 1033428736, 4981766, 827836416, 3951349504, 3861486016]\n"
     ]
    }
   ],
   "source": [
    "def signed_to_unsigned(n, bits=32):\n",
    "    mask = (1 << bits) - 1  # Create bitmask\n",
    "    return n & mask\n",
    "\n",
    "\n",
    "X_tb = []\n",
    "test_1_n,_ = normalize_with_numpy(test_1)\n",
    "print(test_1[0])\n",
    "print(test_1_n[0])\n",
    "\n",
    "for i,x in enumerate(test_1_n[0]):\n",
    "    X_tb.append(signed_to_unsigned(int(norm_to_fixed_32(x))))\n",
    "\n",
    "print(type(X_tb))\n",
    "\n",
    "\n",
    "np.savetxt('layer_1_exit.csv', \n",
    "           X_tb, \n",
    "           fmt='%X',          # Decimal format\n",
    "           delimiter=',',     # Comma-separated\n",
    "           header='',         # No header\n",
    "           comments='')       # No comment characters\n",
    "print(X_tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "9751a47c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.16752437 0.         0.15051463 0.\n",
      "  0.         0.         0.1034645  0.53264534 0.77050054 0.\n",
      "  0.         1.3102565  0.         1.6889466  1.4458104  1.5346419\n",
      "  1.8858335  0.8408802  0.         0.         0.         0.4096307\n",
      "  0.         0.         0.10526977 0.         0.         0.\n",
      "  0.         1.1062775  0.         0.         0.7425416  0.27777687\n",
      "  0.48638934 0.         1.712933   0.         1.2175151  0.\n",
      "  1.0655732  0.         0.         0.         1.7420594  2.77586\n",
      "  0.01395621 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.16611505 0.         0.\n",
      "  0.         1.486958   0.         0.         0.         0.22953513\n",
      "  0.         0.         0.7870524  0.63481724 0.         1.6979332\n",
      "  0.         0.50029165 0.         0.01502359 1.6738992  0.\n",
      "  0.11210147 2.0073228  0.9874821  0.         0.         1.2213451\n",
      "  0.         0.5637371  0.5196267  0.         0.         1.3976003\n",
      "  0.60139745 0.5958304  0.         1.9593477  0.709834   1.0272142\n",
      "  0.747682   0.         0.         0.         0.         0.\n",
      "  0.         1.1853721  0.8699894  0.         0.5529095  1.340857\n",
      "  0.         0.         1.4281418  0.         0.22539659 0.73861086\n",
      "  0.         0.2376017  0.         1.8417127  0.         2.0874033\n",
      "  1.1062405  0.         1.6170973  0.         0.10055792 0.\n",
      "  0.74625784 0.41228378 0.         0.18637069 0.         1.5553371\n",
      "  0.         0.         0.         0.         2.0473657  0.\n",
      "  2.0415175  0.3534723  0.         2.5531483  1.1294616  0.\n",
      "  0.80852777 2.03652    0.         1.370543   0.67705286 0.48249066\n",
      "  0.9748536  0.         1.5960252  0.37443888 0.         0.\n",
      "  0.         2.0345252  0.         1.5493324  0.         0.\n",
      "  1.2731073  0.         0.         0.97805595 1.8798841  0.\n",
      "  0.         0.         0.         1.6690655  0.54454696 0.\n",
      "  0.12969175 0.39045528 0.         0.5406296  0.         0.\n",
      "  0.6813473  0.         1.8280495  0.68219256 0.         0.14992157\n",
      "  0.6627703  0.         0.         2.5656457  0.         0.\n",
      "  0.         0.6410074  1.5260814  0.         0.         1.5409861\n",
      "  1.3790634  0.         0.81451267 0.         1.3714067  0.72379124\n",
      "  0.41508466 0.         1.7491126  0.         2.1781788  0.\n",
      "  0.         0.67252725 1.4260342  0.45807424 0.         0.7018164\n",
      "  0.         0.         0.         2.3463707  2.1608276  0.\n",
      "  1.5891566  0.         0.         4.0325694  0.6513056  0.\n",
      "  0.29552314 0.         2.5584738  0.839441   0.         0.44544637\n",
      "  0.         0.5328033  1.9372739  0.         0.         0.\n",
      "  0.73627406 0.362604   0.         0.0733458  0.         0.6023346\n",
      "  0.17724901 0.         0.6574988  0.         0.14061634 0.04021956\n",
      "  0.         1.2813759  0.23395081 0.7881745  1.4889629  0.87022716\n",
      "  0.         1.5235128  0.7772581  1.208036   1.2124451  0.\n",
      "  0.         0.         0.         0.         0.35437977 0.\n",
      "  0.         0.         0.7550403  0.         0.9380945  0.26054046\n",
      "  0.4190998  2.2747173  1.1532388  0.636524   1.4654205  0.\n",
      "  0.         1.3587713  0.81495714 1.3950448  0.         0.462209\n",
      "  1.7890897  0.         0.12527177 0.         1.0712843  0.\n",
      "  2.2905858  0.         0.01434491 0.23021111 0.         0.7052024 ]]\n"
     ]
    }
   ],
   "source": [
    "print(test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23c440be",
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet_n = LeNet_NN_broken(37)\n",
    "\n",
    "for layer_n, layer in zip(lenet_n.layers,lenet.layers):\n",
    "    layer_n.set_weights(layer.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5c2ad1b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 179ms/step\n",
      "[[-14.616201   -2.5374002  -9.213213   10.514422  -29.521795   18.939688\n",
      "  -21.84362    -6.9485784 -15.871219   -5.5018096]]\n",
      "[[2.6715745e-15 4.7046100e-10 5.9327407e-13 2.1920911e-04 8.9815265e-22\n",
      "  9.9978083e-01 1.9406104e-18 5.7118121e-12 7.6158898e-16 2.4271533e-11]]\n"
     ]
    }
   ],
   "source": [
    "result_n = lenet_n.predict(img_processed)\n",
    "print(result_n)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c50e140c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0000000e+00,  5.2779900e-08, -3.5785011e-08, ...,\n",
       "        -1.4185846e-09,  1.4923333e-09,  9.1320718e-10],\n",
       "       [ 5.2779900e-08,  1.0000000e+00, -7.0199566e-09, ...,\n",
       "        -3.2623835e-09,  3.8577510e-09, -1.0067778e-09],\n",
       "       [-3.5785007e-08,  7.0199584e-09,  1.0000000e+00, ...,\n",
       "        -4.8951876e-10, -1.8148121e-09, -1.0470478e-09],\n",
       "       ...,\n",
       "       [ 1.4185849e-09, -3.2623855e-09, -4.8951754e-10, ...,\n",
       "        -1.0000000e+00,  4.6635111e-07,  6.8266573e-08],\n",
       "       [ 1.4923325e-09, -3.8577488e-09,  1.8148126e-09, ...,\n",
       "         4.6635111e-07,  1.0000000e+00,  1.9781384e-08],\n",
       "       [-9.1320695e-10, -1.0067783e-09, -1.0470474e-09, ...,\n",
       "        -6.8266559e-08,  1.9781417e-08, -1.0000000e+00]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VT[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e8e229b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.6715745e-15 4.7046095e-10 5.9327407e-13 2.1920909e-04 8.9815265e-22\n",
      "  9.9978083e-01 1.9406104e-18 5.7118121e-12 7.6158898e-16 2.4271531e-11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "print(softmax(result_n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6d31ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "784\n",
      "(1, 784) (784, 37) (37, 300)\n",
      "X.shape = (1, 784) | U.shape =(784, 784) | US.shape = (784, 37) |VT.shape = (37, 37) |Y.shape = (1, 37) |H.shape = (784, 37) |\n"
     ]
    }
   ],
   "source": [
    "#Recreate Lenet SVD using weights until layer 2\n",
    "def relu(x):\n",
    "    return x if x > 0 else 0\n",
    "\n",
    "print((len(w0[0])))\n",
    "\n",
    "X = img_processed_tb.T\n",
    "H = np.array(w0[0])\n",
    "H2 = np.array(w1[0])\n",
    "print(X.shape,H.shape,H2.shape)\n",
    "Y =  (X @ H)  #+ w0[1]\n",
    "Y2 = (Y @ H2) #+ w1[1]\n",
    "Y2_relu = []\n",
    "\n",
    "for y in Y2:    \n",
    "    Y2_relu.append(list(map(relu,(y))))\n",
    "U , S , VT = np.linalg.svd(H)\n",
    "US = np.zeros_like(U)\n",
    "\n",
    "for i in range(len(S)):\n",
    "    US[:,i] = U[:,i]*S[i]\n",
    "US = US[:,:len(S)]\n",
    "\n",
    "\n",
    "U2 , S2 , VT2 = np.linalg.svd(H2)\n",
    "US2 = np.zeros_like(U2)\n",
    "\n",
    "for i in range(len(S2)):\n",
    "    US2[:,i] = U2[:,i]*S2[i]\n",
    "US2 = US2[:,:len(S2)]\n",
    "\n",
    "\n",
    "Y_test = w1[1].reshape(1,300)\n",
    "\n",
    "Y_test0 = w0[1].reshape(1,37)\n",
    "\n",
    "data_df = []\n",
    "data_df0 = []\n",
    "for i in range(len(S)):\n",
    "    data_info0 = []\n",
    "    data_info0.append(i)\n",
    "    USX = X @ US[:,i]\n",
    "    data_info0.append(USX[0])\n",
    "    temp = np.outer(USX , VT[i,:])\n",
    "    #for t in temp[0,:]:\n",
    "    #    data_info0.append(t)\n",
    "    Y_test0 += temp\n",
    "    #for y in Y_test[0,:]:\n",
    "    #    data_info.append(y)\n",
    "    data_df0.append(data_info0)\n",
    "\n",
    "for i in range(len(S2)):\n",
    "    data_info = []\n",
    "    data_info.append(i)\n",
    "    USX = Y @ US2[:,i]\n",
    "    data_info.append(USX[0])\n",
    "    temp = np.outer(USX , VT2[i,:])\n",
    "    #for t in temp[0,:]:\n",
    "    #    data_info.append(t)\n",
    "    Y_test += temp\n",
    "    #for y in Y_test[0,:]:\n",
    "    #    data_info.append(y)\n",
    "    data_df.append(data_info)\n",
    "\n",
    "print(f\"{X.shape = } | {U.shape =} | {US.shape = } |{VT.shape = } |{Y.shape = } |{H.shape = } |\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8544428a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.52945785e+00 -4.53769199e-01  1.38171573e-04  4.24034965e-02\n",
      "   1.29348138e-03 -1.43056902e-01  1.51170273e-03  1.33271594e-03\n",
      "   1.55642194e-04  1.88476766e-04 -1.44795607e-01 -5.75763794e-01\n",
      "  -4.86529845e-01  6.03630599e-04 -1.74783192e-03  2.27835264e+00\n",
      "  -1.18108444e-04  3.10362545e-01  2.14822861e-01  1.57141617e-03\n",
      "   9.29150289e-06  8.83605162e-02 -3.89709095e-01  5.60960400e-01\n",
      "   6.35608794e-01 -8.77901925e-04 -3.77040458e-01 -3.46221079e-01\n",
      "   4.13624398e-04 -3.99238165e+00 -5.22401440e-04  1.01780069e+00\n",
      "   1.18859818e-03 -8.52173646e-04 -6.64843645e-04  2.62561559e+00\n",
      "  -1.29588632e+00  7.67226047e-01 -8.17803238e-04 -3.35689945e+00\n",
      "  -1.45140684e+00 -3.42150486e-04  8.48130235e-05 -2.02045572e-01\n",
      "  -5.02799300e+00 -7.77138987e-01 -1.10997527e+00 -1.18553140e-03\n",
      "   1.12345666e+00  2.70650362e-01 -1.72376979e-01  1.22648324e-03\n",
      "   1.51946467e-01  1.35929469e+00  1.41533441e+00 -1.12258673e-04\n",
      "   5.15077560e-03  2.21563095e-04 -1.00389830e-03  6.32411066e-01\n",
      "  -8.05523874e-02 -3.70116694e-01  3.71167547e-01  1.04756382e-03\n",
      "  -7.36351623e-01  9.14825308e-04  2.64286050e+00  4.68041991e-01\n",
      "  -9.88605734e-04  1.04665896e+00  1.20088874e+00  6.28288466e-01\n",
      "   5.67751727e-04  7.88397591e-04  1.05445738e-03 -7.18335950e-01\n",
      "  -1.31617109e-01  7.38575820e-04 -2.19773037e-01  1.03049224e-02\n",
      "  -7.74463697e-04 -8.70631503e-01  5.29471957e-01 -1.62777806e-04\n",
      "   6.40866026e-01 -1.70720985e+00 -5.38890549e-01 -9.95646816e-04\n",
      "   3.75348009e-05  2.53406359e+00  1.69625908e-03 -1.46567496e+00\n",
      "   3.47462442e-04  1.65511765e+00  6.86907091e-03  9.35005805e-05\n",
      "   6.45582368e-04 -1.42936575e-04 -4.35172756e-04 -3.80558070e-01\n",
      "  -3.98273646e-01 -4.85445737e-04  4.84750200e-01  2.26032108e+00\n",
      "  -7.65263342e-01 -3.71236618e-04  3.56221711e-02 -1.43724790e-03\n",
      "  -2.86603517e-01 -2.34910672e+00 -1.20628678e-04 -2.35382313e+00\n",
      "  -4.46412769e-05 -1.16733534e-06 -8.61224147e-01  6.03463705e-01\n",
      "   1.33677687e-01 -4.72003397e-06 -1.28544531e-02 -2.17982097e-04\n",
      "  -1.57997788e-03 -3.91395990e-01  1.33613329e-04  7.84389212e-04\n",
      "   6.61366484e-01  4.25896213e-02 -4.07951095e-04  8.59851940e-04\n",
      "  -3.50257571e-05 -2.06946778e-04  6.69747021e-04  4.50243931e-01\n",
      "   4.64616344e-01 -4.58482382e-04 -5.06168187e-04 -1.04963603e+00\n",
      "  -1.49206218e+00  1.05760270e-03  3.65224723e-04 -7.86225765e-01\n",
      "   2.10866681e-05 -5.58083072e-05  2.58715758e-01 -2.54344181e-02\n",
      "  -1.58605588e-02 -1.11577553e-01  3.54977847e-04 -8.78000862e-04\n",
      "   4.51931246e-01 -6.08880869e-04 -1.35445317e-03  8.04550646e-02\n",
      "  -1.04139224e-03 -1.15571010e-03 -9.18422145e-01 -4.55826083e-04\n",
      "   3.36622239e-01 -1.63134608e-01  4.19363085e-04 -1.37346622e-03\n",
      "   7.22907978e-04 -1.86668412e-01  4.36364762e-02 -1.25436433e-01\n",
      "  -4.63340251e-01  1.06392143e-03  1.07711565e+00  4.34449881e-04\n",
      "   5.39482542e-04  8.50536305e-01 -3.76271728e-01  2.51732854e-02\n",
      "   4.64243248e-04 -8.16628795e-01 -7.12264832e-02 -5.91489737e-01\n",
      "  -1.74750461e+00  1.84173419e+00  2.74999841e+00 -2.74265823e-01\n",
      "   2.05609237e+00  9.72649170e-04 -7.02613413e-04  5.32021555e-05\n",
      "  -3.00349418e-01 -2.18798002e-01  1.06349062e+00 -1.22962376e-01\n",
      "  -2.86575617e-01  5.48027603e-01  2.17383130e-04 -2.78040235e+00\n",
      "   4.38179303e-01  5.57965214e-04  3.42737446e+00  1.41859720e-03\n",
      "   1.35696648e-01 -2.65883765e+00  1.01509819e-03  3.24433529e-04\n",
      "  -2.23125403e-04 -1.25713774e-03 -1.15814673e-03 -2.06200192e-04\n",
      "  -7.00355487e-01  1.07256452e+00 -2.06157939e+00 -4.33012340e-01\n",
      "  -1.02951122e+00 -1.48388320e+00  1.45075621e-04 -4.55510126e-04\n",
      "  -8.25724817e-05 -1.01162172e-03  1.60243950e-03 -1.43654339e-01\n",
      "   3.34058883e-01  7.92656960e-01  2.02884693e-04 -1.36803157e-03\n",
      "   2.74714059e-04  2.84194519e-04 -1.30056088e+00 -3.72741384e+00\n",
      "  -7.99967829e-04  1.32086529e-03  3.25851307e-04 -2.43738389e-01\n",
      "  -8.42543399e-01  1.46704002e+00  3.25499556e-04 -2.29831499e-04\n",
      "   5.66671717e-04 -1.80626461e-01  4.03595060e-01 -4.39004481e-01\n",
      "   7.31074503e-04  1.32322607e-01  3.45172563e-04  1.60982363e+00\n",
      "  -4.01953776e-04 -9.69736583e-01 -1.03870884e-03 -3.13454164e+00\n",
      "  -8.04405312e-01  2.90828504e-01 -2.27618528e+00  2.29037757e-05\n",
      "   2.38280684e-01  1.80375935e-01  2.51519372e-04  7.17665150e-01\n",
      "  -6.82392250e-04 -5.57409647e-01 -1.93693265e+00 -1.93574627e+00\n",
      "   2.98107667e-04  2.62294082e-03 -5.96418416e-02  7.07107882e-04\n",
      "  -2.66537565e+00  9.44971150e-06  4.31389777e-02  3.43084332e-05\n",
      "  -1.01979451e+00 -3.54692937e-04  9.84978284e-06  1.21794695e-03\n",
      "  -4.13044153e-01  1.19182922e+00 -3.85100741e-04  2.95080538e-05\n",
      "   1.17340756e-04 -3.67652390e-04  5.90956941e-01 -2.28650907e-01\n",
      "  -2.51614917e+00 -1.23149670e-01  1.32758718e+00  7.55802236e-04\n",
      "   6.82857499e-05  8.95498821e-05 -3.37478765e-02  1.90608592e-04\n",
      "   9.26639578e-04  1.02073251e-02 -5.98859778e-01 -3.48513993e-04\n",
      "  -1.00393563e-01 -5.29965079e-01 -6.63638609e-01  1.43306020e-01\n",
      "  -9.27262807e-04  1.08794380e-01 -2.16737311e+00  3.02240650e-01\n",
      "   6.71416339e-04 -9.17769195e-01  1.67743503e+00 -8.26979358e-01]]\n",
      "[[-1.0000000e+00  5.2779900e-08 -3.5785011e-08 ... -1.4185846e-09\n",
      "   1.4923333e-09  9.1320718e-10]\n",
      " [ 5.2779900e-08  1.0000000e+00 -7.0199566e-09 ... -3.2623835e-09\n",
      "   3.8577510e-09 -1.0067778e-09]\n",
      " [-3.5785007e-08  7.0199584e-09  1.0000000e+00 ... -4.8951876e-10\n",
      "  -1.8148121e-09 -1.0470478e-09]\n",
      " ...\n",
      " [ 1.4185849e-09 -3.2623855e-09 -4.8951754e-10 ... -1.0000000e+00\n",
      "   4.6635111e-07  6.8266573e-08]\n",
      " [ 1.4923325e-09 -3.8577488e-09  1.8148126e-09 ...  4.6635111e-07\n",
      "   1.0000000e+00  1.9781384e-08]\n",
      " [-9.1320695e-10 -1.0067783e-09 -1.0470474e-09 ... -6.8266559e-08\n",
      "   1.9781417e-08 -1.0000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(Y2)\n",
    "print(VT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "47f42f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-2.323594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5.337052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.686502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-2.912908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-2.875251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-1.758965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-3.871732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-0.649270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-3.090874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>-0.366343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>0.424738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>-1.939303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>3.513880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0.026791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>-1.678901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2.846831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1.167374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>4.797930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>2.537441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>3.192867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>1.598980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>2.488234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>-4.578110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>-0.174624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>-7.128281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1.810756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>1.127577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>-1.848403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>0.944369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>1.497101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>3.038505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>-0.098382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>-3.430330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>-0.016536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>-2.747894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>-1.140593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>1.438884</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0         1\n",
       "0    0 -2.323594\n",
       "1    1  5.337052\n",
       "2    2  1.686502\n",
       "3    3 -2.912908\n",
       "4    4 -2.875251\n",
       "5    5 -1.758965\n",
       "6    6 -3.871732\n",
       "7    7 -0.649270\n",
       "8    8 -3.090874\n",
       "9    9 -0.366343\n",
       "10  10  0.424738\n",
       "11  11 -1.939303\n",
       "12  12  3.513880\n",
       "13  13  0.026791\n",
       "14  14 -1.678901\n",
       "15  15  2.846831\n",
       "16  16  1.167374\n",
       "17  17  4.797930\n",
       "18  18  2.537441\n",
       "19  19  3.192867\n",
       "20  20  1.598980\n",
       "21  21  2.488234\n",
       "22  22 -4.578110\n",
       "23  23 -0.174624\n",
       "24  24 -7.128281\n",
       "25  25  1.810756\n",
       "26  26  1.127577\n",
       "27  27 -1.848403\n",
       "28  28  0.944369\n",
       "29  29  1.497101\n",
       "30  30  3.038505\n",
       "31  31 -0.098382\n",
       "32  32 -3.430330\n",
       "33  33 -0.016536\n",
       "34  34 -2.747894\n",
       "35  35 -1.140593\n",
       "36  36  1.438884"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_df0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9cb588b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-5.274517e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-5.123261e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.802420e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.219638e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.570096e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>-2.106216e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>-9.621696e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>-2.498457e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>-1.970198e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>4.905303e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>-2.735365e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>-3.571264e-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>2.325433e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>1.762503e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>-1.150602e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>3.369545e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>1.151888e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>-9.181460e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>5.141014e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>1.373859e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>-1.611923e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>5.235651e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>-3.402432e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>5.180981e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>-1.131023e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>1.004459e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>-1.897959e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>-1.606505e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>2.293340e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>-1.857988e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>30</td>\n",
       "      <td>1.513535e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31</td>\n",
       "      <td>4.946190e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>32</td>\n",
       "      <td>4.047342e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>33</td>\n",
       "      <td>-9.782041e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>34</td>\n",
       "      <td>-4.693603e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>35</td>\n",
       "      <td>3.147080e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>36</td>\n",
       "      <td>4.959269e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0             1\n",
       "0    0 -5.274517e+02\n",
       "1    1 -5.123261e-07\n",
       "2    2 -1.802420e-06\n",
       "3    3  1.219638e-06\n",
       "4    4 -1.570096e-06\n",
       "5    5 -2.106216e-06\n",
       "6    6 -9.621696e-07\n",
       "7    7 -2.498457e-07\n",
       "8    8 -1.970198e-06\n",
       "9    9  4.905303e-06\n",
       "10  10 -2.735365e-06\n",
       "11  11 -3.571264e-08\n",
       "12  12  2.325433e-06\n",
       "13  13  1.762503e-06\n",
       "14  14 -1.150602e-06\n",
       "15  15  3.369545e-06\n",
       "16  16  1.151888e-06\n",
       "17  17 -9.181460e-07\n",
       "18  18  5.141014e-07\n",
       "19  19  1.373859e-06\n",
       "20  20 -1.611923e-07\n",
       "21  21  5.235651e-07\n",
       "22  22 -3.402432e-07\n",
       "23  23  5.180981e-07\n",
       "24  24 -1.131023e-06\n",
       "25  25  1.004459e-06\n",
       "26  26 -1.897959e-06\n",
       "27  27 -1.606505e-06\n",
       "28  28  2.293340e-06\n",
       "29  29 -1.857988e-06\n",
       "30  30  1.513535e-06\n",
       "31  31  4.946190e-07\n",
       "32  32  4.047342e-07\n",
       "33  33 -9.782041e-07\n",
       "34  34 -4.693603e-07\n",
       "35  35  3.147080e-06\n",
       "36  36  4.959269e+00"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data_df)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc85d7bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.26857463  0.11653159 -0.03921171  0.3379265  -0.11215492 -0.05069784\n",
      " -0.01574498 -0.07947755 -0.04679665 -0.13859864 -0.17103831  0.11341953\n",
      "  0.29205248 -0.01493471 -0.13107313  0.01520232 -0.0174751   0.05377271\n",
      " -0.33874756 -0.00943521 -0.01615655 -0.08488752  0.33888295  0.05655032\n",
      "  0.19301003 -0.01016331 -0.03299653  0.02159429 -0.01120275  0.41458073\n",
      " -0.0205394   0.09969426 -0.20669778 -0.07146092 -0.0085628   0.02664064\n",
      "  0.19696796 -0.21724004 -0.07529428  0.00544734 -0.19035766 -0.07074089\n",
      " -0.01662887  0.04591956  0.31902382  0.36379084 -0.00366823 -0.00825527\n",
      "  0.08657182 -0.06879878 -0.04655615 -0.02881224 -0.0990693   0.15883671\n",
      " -0.06439045 -0.00712355 -0.03220049 -0.04481666 -0.00914741 -0.50608665\n",
      " -0.03217473 -0.02538256 -0.04552635 -0.01192292  0.15831415 -0.04273221\n",
      " -0.10854637  0.0268755  -0.01593244 -0.3005913  -0.08288822 -0.24838582\n",
      " -0.02632396 -0.01005456 -0.01806499 -0.3336969  -0.09432822 -0.01424101\n",
      "  0.18302883 -0.1520102  -0.10035869  0.2509785  -0.07188867 -0.0339052\n",
      " -0.3384106   0.17983332 -0.40086254 -0.14297478 -0.18598711 -0.26390094\n",
      " -0.01397317  0.24175906 -0.02181219 -0.29345107 -0.16578339 -0.01578764\n",
      " -0.01044108 -0.02439234 -0.08805943  0.07708232  0.2761848  -0.01821056\n",
      " -0.35433647  0.06728865  0.4173812  -0.01435129 -0.24410243 -0.01195409\n",
      "  0.14964     0.36248878 -0.03243265  0.41864836 -0.10766402 -0.05650862\n",
      " -0.33469027  0.10805871 -0.28173378 -0.00995513  0.08028661 -0.02881016\n",
      " -0.15009868 -0.05272995 -0.16695625 -0.13446145  0.13436018 -0.05583381\n",
      " -0.02833684 -0.01823712 -0.0089433  -0.0364944  -0.02775235 -0.02611762\n",
      "  0.09913846 -0.05763981 -0.02653462  0.378256    0.12008633 -0.01391187\n",
      " -0.01391133 -0.17417477 -0.07514464 -0.01676693 -0.04225368  0.21818495\n",
      "  0.25660348 -0.10212707 -0.13234095 -0.00851657 -0.15792616 -0.05828892\n",
      " -0.0787128  -0.2005951  -0.01053711 -0.07030119 -0.10943152 -0.02035353\n",
      "  0.0816573  -0.40241742 -0.14296529 -0.05405069 -0.01848589 -0.37092584\n",
      " -0.05762487  0.11680964  0.13282385 -0.01698649  0.16304916 -0.04765931\n",
      " -0.03796296 -0.11858556 -0.20872575 -0.10045835 -0.01170126 -0.08198962\n",
      " -0.16843872 -0.19803806  0.2219266  -0.15369067  0.05887632 -0.13703237\n",
      " -0.21019731 -0.02037915 -0.05519481 -0.01339196 -0.10231905  0.23811388\n",
      " -0.17303221 -0.05928164  0.38805947  0.18190154 -0.01629845 -0.20114788\n",
      "  0.15308285 -0.0796495  -0.04810602 -0.01152115 -0.21457097 -0.19379641\n",
      " -0.22064206 -0.02769594 -0.03834671 -0.00872109 -0.01349484 -0.0149306\n",
      " -0.11022815 -0.14382163  0.05072037 -0.00129796 -0.1522539   0.03152772\n",
      " -0.00796497 -0.01362223 -0.00971263 -0.06799939 -0.02345108 -0.17339306\n",
      "  0.02784933  0.12548572 -0.02138575 -0.00981284 -0.02806247 -0.02620787\n",
      "  0.08989096 -0.10360283 -0.03196925 -0.0371065  -0.02545987 -0.1275617\n",
      "  0.15497597 -0.15647474 -0.0114952  -0.00751181 -0.00777618 -0.25859022\n",
      "  0.08158189 -0.01156757 -0.01258501 -0.10138296 -0.01746696 -0.41853496\n",
      " -0.02144954  0.34563962 -0.01422665 -0.00175467 -0.11834008 -0.14216197\n",
      "  0.37811834 -0.06451129 -0.1490962  -0.23758838 -0.01114819  0.4111463\n",
      " -0.09640305  0.01382196  0.10084686  0.24376208 -0.12621658 -0.02798637\n",
      " -0.05468936 -0.10357284  0.1711997  -0.19594027 -0.28552324 -0.02511807\n",
      " -0.02477909 -0.01140575 -0.08651619 -0.05362956 -0.27091086  0.09090588\n",
      " -0.02393461 -0.02153333 -0.00696794 -0.1439364   0.2833683   0.01251866\n",
      " -0.03103722  0.00380265 -0.3909756  -0.02411854 -0.01737023 -0.11963589\n",
      " -0.03734555 -0.07417985 -0.03050532 -0.1549872  -0.4774242  -0.07903407\n",
      "  0.06121509 -0.2938148  -0.32488906 -0.01803693 -0.01263414 -0.09827661\n",
      "  0.19826844 -0.23485298 -0.08936901  0.08117363 -0.07293184 -0.04347133]\n"
     ]
    }
   ],
   "source": [
    "print (w1[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7f9b2187",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.32359399  5.33705205  1.68650199 -2.91290789  2.87525063  1.75896574\n",
      "   3.87173207  0.64927052  3.09087423 -0.36634363 -0.42473805 -1.93930306\n",
      "  -3.51387976 -0.02679064  1.6789015   2.84683081 -1.16737453  4.7979307\n",
      "  -2.53744028  3.19286705  1.59898031 -2.48823397  4.57810914 -0.17462273\n",
      "   7.12828105 -1.81075459 -1.12757663  1.84840495  0.94436889 -1.49710182\n",
      "  -3.03850454  0.09838142  3.43033007  0.01653623  2.74789343 -1.14059371\n",
      "  -1.43888371]]\n"
     ]
    }
   ],
   "source": [
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "22c0558a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(w0[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3bb267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87046fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
